{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "QuarantineSports.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabor132/QuarantineSportsClassifier/blob/master/src/QuarantineSportsCreateModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vayM6pl1hDcd",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Quarantine Sports Classifier "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b094aVxOhJnf",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ar4UBA-mhFyJ",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH9guuXpw09P",
        "colab_type": "text"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcY0e3PTw2jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "testing_data_percentage = 0.2\n",
        "nr_of_frames_per_sequence = 15\n",
        "nr_of_keypoints = 25\n",
        "nr_of_values_per_keypoint = 3\n",
        "\n",
        "all_files_names = [\"video1.json\", \"video2.json\", \"video3.json\"]\n",
        "\n",
        "# Dataset paths\n",
        "DRAGOS_COLAB_DATASET_PATH = \"/content/drive/My Drive/QuarantineSportsDatasets/Dataset/OpenPoseDataset/\"\n",
        "LOCAL_DATASET_PATH = \"../datasets/\"\n",
        "\n",
        "# Model paths\n",
        "DRAGOS_COLAB_MODEL_PATH = \"/content/drive/My Drive/QuarantineSportsDatasets/Model/\"\n",
        "LOCAL_MODEL_PATH = \"../\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u1vWejYa1Ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_dataset_path = DRAGOS_COLAB_DATASET_PATH\n",
        "current_model_path = DRAGOS_COLAB_MODEL_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cENXg0S81Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_paths = []\n",
        "for path in all_files_names:\n",
        "  dataset_path = current_dataset_path + path\n",
        "  dataset_paths.append(dataset_path)\n",
        "\n",
        "print(\"All files found: {}\".format(dataset_paths))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Naobi1hABh",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Load Datasets and create X and Y\n",
        "\n",
        "## Important to know\n",
        "\n",
        "1.   Out of open pose we extract for all frames all the 25 keypoints (each keypoint contains the X, Y and score)\n",
        "2.   The Category exists per frame and is 0/1 as in Wrong/Correct as in Not a Push-Up Frame/Is a Push Up Frame\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agJssUaRasLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_total = None\n",
        "x_total = None\n",
        "for (index, path) in enumerate(dataset_paths):\n",
        "  print(\"For file at {}\".format(path))\n",
        "  df = pd.read_json(path)\n",
        "  keypoints = df['Keypoints'].values\n",
        "  file_y = df['Category'].values\n",
        "  file_x = []\n",
        "  for k in keypoints:\n",
        "      if k != None:\n",
        "          newK = np.reshape(np.asarray(k), (25,3))\n",
        "          file_x.append(newK)\n",
        "      else:\n",
        "          file_x.append(np.reshape(np.zeros(75), (25,3)))\n",
        "  file_x = np.array(file_x)\n",
        "  print(\"X: {} and Y: {}\".format(file_x.shape, file_y.shape))\n",
        "  if np.all(x_total == None):\n",
        "    x_total = file_x\n",
        "  else:\n",
        "    x_total = np.vstack((x_total, file_x))\n",
        "  if np.all(y_total == None):\n",
        "    y_total = file_y\n",
        "  else:\n",
        "    y_total = np.hstack((y_total, file_y))\n",
        "print(\"Total X: {}\".format(x_total.shape))\n",
        "print(\"Total Y: {}\".format(y_total.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcT9VZ-QoK9Q",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into categories (wrong and correct)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WryRhwOooJvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get Indexes\n",
        "y_wrong_index = np.where(y_total == 0)\n",
        "y_correct_index = np.where(y_total == 1)\n",
        "# Get Values\n",
        "x_wrong = x_total[y_wrong_index]\n",
        "y_wrong = y_total[y_wrong_index]\n",
        "x_correct = x_total[y_correct_index]\n",
        "y_correct = y_total[y_correct_index]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oq8rBRLoKZc",
        "colab_type": "text"
      },
      "source": [
        "## Further splitting the frames into sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbPD8W4EqTxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Initial shapes\")\n",
        "print(\"y_wrong: {}\".format(y_wrong.shape))\n",
        "print(\"y_correct: {}\".format(y_correct.shape))\n",
        "print(\"x_wrong: {}\".format(x_wrong.shape))\n",
        "print(\"x_correct: {}\".format(x_correct.shape))\n",
        "\n",
        "class FrameSet:\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "def get_maximum_number_of_usable_frames(a):\n",
        "  divider = nr_of_frames_per_sequence\n",
        "  i = 1\n",
        "  while (divider * i) < len(a):\n",
        "    i = i + 1\n",
        "  return divider * (i-1)\n",
        "\n",
        "def transform_y_into_frame_sets(a):\n",
        "  number_of_sets = get_maximum_number_of_usable_frames(a)\n",
        "  print(\"Number of sets: {}\".format(number_of_sets))\n",
        "  new_y = None\n",
        "  if np.any(a == 0):\n",
        "    new_y = np.zeros((int) (number_of_sets / nr_of_frames_per_sequence))\n",
        "  else:\n",
        "    new_y = np.ones((int) (number_of_sets / nr_of_frames_per_sequence))\n",
        "  return new_y\n",
        "\n",
        "def transform_x_into_frame_sets(a):\n",
        "  number_of_sets = get_maximum_number_of_usable_frames(a)\n",
        "  print(\"Number of sets: {}\".format(number_of_sets))\n",
        "  sub_group_size = a[0:number_of_sets]\n",
        "  return np.reshape(sub_group_size, ((int) (number_of_sets / nr_of_frames_per_sequence), nr_of_frames_per_sequence, nr_of_keypoints * nr_of_values_per_keypoint))\n",
        "\n",
        "y_wrong = transform_y_into_frame_sets(y_wrong)\n",
        "y_correct = transform_y_into_frame_sets(y_correct)\n",
        "x_wrong = transform_x_into_frame_sets(x_wrong)\n",
        "x_correct = transform_x_into_frame_sets(x_correct)\n",
        "print(\"After reshaping\")\n",
        "print(\"y_wrong: {}\".format(y_wrong.shape))\n",
        "print(\"y_correct: {}\".format(y_correct.shape))\n",
        "print(\"x_wrong: {}\".format(x_wrong.shape))\n",
        "print(\"x_correct: {}\".format(x_correct.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUOVmJhMvn3s",
        "colab_type": "text"
      },
      "source": [
        "## Recompine all wrong and correct arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NfEBzGJvl5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only stack them when they are not empty\n",
        "x_processed = None\n",
        "y_processed = None\n",
        "x_processed = np.concatenate((x_correct, x_wrong))\n",
        "y_processed = np.concatenate((y_correct, y_wrong))\n",
        "y_processed = to_categorical(y_processed)\n",
        "print(x_processed.shape)\n",
        "print(y_processed.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gveOynHwpAr",
        "colab_type": "text"
      },
      "source": [
        "## Finally, split them into training and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoOaqvu1v8Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_processed, y_processed, test_size=0.2)\n",
        "print(\"Number of training Frame Sets {} and number of testing Frame sets {}\".format(len(x_train), len(x_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKpqu9xqyUuZ",
        "colab_type": "text"
      },
      "source": [
        "## Defining the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAxT0lF6xRoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_train.shape)\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.LSTM(15, input_shape=(15, 75), activation='softmax'))\n",
        "model.add(keras.layers.Dropout(0.2, input_shape=(15,)))\n",
        "#model.add(keras.layers.Conv1D(3, 3, activation='softmax'))\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "model.build(input_shape=(1, 75))\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),loss='categorical_crossentropy',\n",
        "              metrics=[keras.metrics.categorical_crossentropy])\n",
        "model.summary()\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3uAeb4Em6NN",
        "colab_type": "text"
      },
      "source": [
        "## Saving Model to JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_xj1aCJX_Vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(current_model_path + \"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(current_model_path + \"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SebX2gYurL_B",
        "colab_type": "text"
      },
      "source": [
        "## Finish"
      ]
    }
  ]
}