{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "QuarantineSports.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabor132/QuarantineSportsClassifier/blob/master/src/QuarantineSports.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vayM6pl1hDcd",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Quarantine Sports Classifier "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b094aVxOhJnf",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ar4UBA-mhFyJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6185feb-c8e2-4535-d3af-d79f670acae6"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH9guuXpw09P",
        "colab_type": "text"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcY0e3PTw2jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.1\n",
        "testing_data_percentage = 0.2\n",
        "nr_of_frames_per_sequence = 15\n",
        "nr_of_keypoints = 25\n",
        "nr_of_values_per_keypoint = 3\n",
        "dataset_path = \"/content/drive/My Drive/QuarantineSportsDatasets/Dataset/OpenPoseDataset/video2.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Naobi1hABh",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Load Dataset and create X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agJssUaRasLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_json(dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkxF8CUVhZ2F",
        "colab_type": "text",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Important to know\n",
        "\n",
        "1.   Out of open pose we extract for all frames all the 25 keypoints (each keypoint contains the X, Y and score)\n",
        "2.   The Category exists per frame and is 0/1 as in Wrong/Correct as in Not a Push-Up Frame/Is a Push Up Frame\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G5c_rBlawl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "keypoints = df['Keypoints'].values\n",
        "y_total = df['Category'].values\n",
        "\n",
        "\n",
        "xList = []\n",
        "for k in keypoints:\n",
        "    if k != None:\n",
        "        newK = np.reshape(np.asarray(k), (25,3))\n",
        "        xList.append(newK)\n",
        "    else:\n",
        "        xList.append(np.reshape(np.zeros(75), (25,3)))\n",
        "x_total = np.array(xList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcT9VZ-QoK9Q",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into categories (wrong and correct)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WryRhwOooJvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get Indexes\n",
        "y_wrong_index = np.where(y_total == 0)\n",
        "y_correct_index = np.where(y_total == 1)\n",
        "# Get Values\n",
        "x_wrong = x_total[y_wrong_index]\n",
        "y_wrong = y_total[y_wrong_index]\n",
        "x_correct = x_total[y_correct_index]\n",
        "y_correct = y_total[y_correct_index]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oq8rBRLoKZc",
        "colab_type": "text"
      },
      "source": [
        "## Further splitting the frames into sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbPD8W4EqTxq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "36fc1fcf-e819-464b-c231-8ec70670d348"
      },
      "source": [
        "print(\"Initial shapes\")\n",
        "print(y_wrong.shape)\n",
        "print(y_correct.shape)\n",
        "print(x_wrong.shape)\n",
        "print(x_correct.shape)\n",
        "\n",
        "class FrameSet:\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "def get_maximum_number_of_usable_frames(a):\n",
        "  divider = nr_of_frames_per_sequence\n",
        "  i = 1\n",
        "  while (divider * i) < len(a):\n",
        "    i = i + 1\n",
        "  return divider * (i-1)\n",
        "\n",
        "def transform_y_into_frame_sets(a):\n",
        "  number_of_sets = get_maximum_number_of_usable_frames(a)\n",
        "  print(\"Number of sets: {}\".format(number_of_sets))\n",
        "  sub_group_size = a[0:number_of_sets]\n",
        "  return np.reshape(sub_group_size, (nr_of_frames_per_sequence, (int) (number_of_sets / nr_of_frames_per_sequence)))\n",
        "\n",
        "def transform_x_into_frame_sets(a):\n",
        "  number_of_sets = get_maximum_number_of_usable_frames(a)\n",
        "  print(\"Number of sets: {}\".format(number_of_sets))\n",
        "  sub_group_size = a[0:number_of_sets]\n",
        "  return np.reshape(sub_group_size, (nr_of_frames_per_sequence, (int) (number_of_sets / nr_of_frames_per_sequence), nr_of_keypoints, nr_of_values_per_keypoint))\n",
        "\n",
        "#y_wrong = transform_y_into_frame_sets(y_wrong)\n",
        "#y_correct = transform_y_into_frame_sets(y_correct)\n",
        "#x_wrong = transform_x_into_frame_sets(x_wrong)\n",
        "#x_correct = transform_x_into_frame_sets(x_correct)\n",
        "print(\"After reshaping\")\n",
        "print(y_wrong.shape)\n",
        "print(y_correct.shape)\n",
        "print(x_wrong.shape)\n",
        "print(x_correct.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial shapes\n",
            "(2317,)\n",
            "(0,)\n",
            "(2317, 25, 3)\n",
            "(0, 25, 3)\n",
            "After reshaping\n",
            "(2317,)\n",
            "(0,)\n",
            "(2317, 25, 3)\n",
            "(0, 25, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUOVmJhMvn3s",
        "colab_type": "text"
      },
      "source": [
        "## Recompine all wrong and correct arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NfEBzGJvl5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "61313b44-f9b5-4798-920b-8eea49342b51"
      },
      "source": [
        "# Only stack them when they are not empty\n",
        "x_processed = None\n",
        "y_processed = None\n",
        "if np.any(x_correct != 0) and np.any(x_wrong != 0):\n",
        "  x_processed = np.hstack((x_correct, x_wrong))\n",
        "elif np.any(x_correct != 0):\n",
        "  x_processed = x_correct\n",
        "elif np.any(x_wrong != 0):\n",
        "  x_processed = x_wrong\n",
        "if np.any(y_correct != 0) and np.any(y_wrong != 0):\n",
        "  y_processed = np.hstack((y_correct, y_wrong))\n",
        "elif len(y_wrong) > 0:\n",
        "  y_processed = y_wrong\n",
        "elif len(y_correct) > 0:\n",
        "  y_processed = y_correct\n",
        "print(x_processed.shape)\n",
        "print(y_processed)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2317, 25, 3)\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gveOynHwpAr",
        "colab_type": "text"
      },
      "source": [
        "## Finally, split them into trainint and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoOaqvu1v8Jj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea25fe73-9a35-4841-e8ea-108d37b1bdee"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_processed, y_processed, test_size=0.2)\n",
        "print(\"Number of training Frame Sets {} and number of testing Frame sets {}\".format(len(x_train), len(x_test)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training Frame Sets 1853 and number of testing Frame sets 464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKpqu9xqyUuZ",
        "colab_type": "text"
      },
      "source": [
        "## Defining the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAxT0lF6xRoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4135ccb-fda3-4268-ed39-82fe65500b4e"
      },
      "source": [
        "print(x_train.shape)\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(15, activation='relu', input_shape=(25,3)))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1853, 25, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X2oB944ymZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "b584187d-5baa-4058-9d7c-71f94e88f38d"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=30, batch_size=nr_of_frames_per_sequence)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-783b9ec95843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnr_of_frames_per_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have 3 dimensions, but got array with shape (1853, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCYzQjQaEu4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}